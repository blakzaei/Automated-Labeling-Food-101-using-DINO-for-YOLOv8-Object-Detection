{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33884,"sourceType":"datasetVersion","datasetId":1864}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Install ultralytics for YOLO -------------------------------------------------------------------------\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Install GroundingDINO for Zero-Shot ---------------------------------------------------------------------\n%cd /kaggle/working/  \n\n!git clone https://github.com/IDEA-Research/GroundingDINO.git\n\n%cd GroundingDINO/\n!pip install -e .\n\n!mkdir weights\n%cd weights\n!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n\n%cd /kaggle/working/GroundingDINO    \n\n#-- clear output --\nfrom IPython import display\ndisplay.clear_output()  \n\n!python -c \"import groundingdino\" && echo \"Module installed successfully\" || echo \"Module installation failed\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Import -----------------------------------------------------------------------------------------------\n%cd /kaggle/working/GroundingDINO\nfrom groundingdino.util.inference import load_model as dn_load_model\nfrom groundingdino.util.inference import load_image as dn_load_image\nfrom groundingdino.util.inference import predict as dn_predict\nfrom groundingdino.util.inference import annotate as dn_annotate\n%cd /kaggle/working\n\nfrom ultralytics import YOLO\nimport yaml\n\nimport torch\n\nimport pandas as pd\nimport numpy as np\n\nimport os\nimport shutil\nimport PIL\nimport random\nimport cv2\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize -------------------------------------------------------------------\noutput_path = '/kaggle/working/'\ninput_path = '/kaggle/input/'\n\nmodel_config_file = output_path + 'GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\nmodel_weights_file = output_path + 'GroundingDINO/weights/groundingdino_swint_ogc.pth'\n\nds_path = input_path + 'food41/images/'\n\ndino_imgs_path = output_path + 'dino_results/images/'\ndino_lbls_path = output_path + 'dino_results/labels/'\n\ntrain_dir = output_path + 'yolo_train/images/'\nval_dir = output_path + 'yolo_valid/images/'\ntest_dir = output_path + 'yolo_test/images/'\n\ntrain_lbl_dir = output_path + 'yolo_train/labels/'\nval_lbl_dir = output_path + 'yolo_valid/labels/'\ntest_lbl_dir = output_path + 'yolo_test/labels/'\n\ndata_config_file = output_path + 'data.yaml'\ntest_data_config_file = output_path + 'test_data.yaml'\n\nNUM_EPOCHS = 100\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:' , DEVICE)\n\nPROJECT = 'model_yolo'\n\nCONF_THRESHOLD = 0.5\nIOU_THRESHOLD = 0.6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Get All Images from DS -----------------------------------------------------------\nimage_files = []\nfor root, dirs, files in os.walk(ds_path):\n    for file in files:\n        if file.endswith('.jpg'):\n            image_files.append(os.path.join(root, file)) \n    \ntotal_images = len(image_files)\nprint('total_images:' , total_images)  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_image_files = random.sample(image_files, 100)\nsampled_images_to_show = random.sample(sampled_image_files, 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_boxes(image, boxes, logits, phrases):\n    \n    annotated_img = dn_annotate(image_source=image,\n                                    boxes=boxes,\n                                    logits=logits,\n                                    phrases=phrases)\n        \n    out_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)        \n    plt.imshow(out_img, interpolation = 'bicubic')\n    plt.xticks([]), plt.yticks([])        \n    plt.show()   \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Run DINO and predict Bounding Boxes for Objects ------------------------------------------\ndef run_dino(model_dino, image, text_prompt='food', box_threshold=0.4, text_threshold=0.1):\n    boxes, logits, phrases = dn_predict(\n        model = model_dino,\n        image = image,\n        caption = text_prompt,\n        box_threshold = box_threshold,\n        text_threshold = text_threshold\n    )\n    return boxes, logits, phrases","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Annotate All Images with predicted bounding boxes ------------------------------------\ndef annotate(dino, image_files, result_imgs_path, result_lbls_path):\n    \n    os.makedirs(result_imgs_path, exist_ok=True)\n    os.makedirs(result_lbls_path, exist_ok=True)\n    \n    i = 1\n    for img_file in image_files:\n        \n        #-- log --\n        if i==1 or i%100==0:\n            print(f'annotating {i}th image -------------')\n        \n        title = 'img_' + str(i)\n        image_path = result_imgs_path + title + '.png'\n        label_path = result_lbls_path + title + '.txt'\n        \n        img = PIL.Image.open(img_file)\n        img = img.resize((640, 640))\n        img.save(image_path)\n        \n        image_source, image = dn_load_image(image_path)\n        boxes, logits, phrases = run_dino(dino, image)\n        \n        label = ['0 ' + ' '.join(list(map(str, b))) for b in boxes.tolist()]\n        label = '\\n'.join(label)\n        with open(label_path, 'w') as f:\n            f.write(label)\n            \n        if img_file in sampled_images_to_show:\n            plot_boxes(image_source, boxes, logits, phrases)\n        \n        i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Create a dino model --------------------------------------------------------\nmodel_dino = dn_load_model(model_config_file,model_weights_file, device= DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Annotate All Images --------------------------------------------------------\nannotate(dino = model_dino ,\n         image_files = sampled_image_files,\n         result_imgs_path = dino_imgs_path,\n         result_lbls_path = dino_lbls_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Split Dataset to Train, Test, and Validation --------------------------------------------------\ndef split_dataset(img_source_dir, lbl_source_dir, train_dir, test_dir, val_dir, train_lbl_dir, test_lbl_dir, val_lbl_dir, split_ratio=(0.7, 0.1, 0.2)):\n    \n    image_files = [file for file in os.listdir(img_source_dir) if file.endswith('.png')]\n    labels_file = [file for file in os.listdir(lbl_source_dir) if file.endswith('.txt')]\n    total_images = len(image_files)\n    \n    print('total_images:' , total_images) \n    print('labels_file:' , len(labels_file))\n\n    # Calculate the number of files for each split\n    num_train = int(split_ratio[0] * total_images)\n    num_test = int(split_ratio[1] * total_images)\n    num_validation = total_images - num_train - num_test\n    \n    print(f'train_size = {num_train}\\nval_size = {num_validation}\\ntest_size = {num_test}')    \n\n    # Randomly shuffle the list of files\n    random.shuffle(image_files)\n    \n    # Remove existing train, test, and validation directories\n    for directory in [train_dir, test_dir, val_dir, train_lbl_dir, test_lbl_dir, val_lbl_dir]:\n        if os.path.exists(directory):\n            shutil.rmtree(directory)\n\n    # Create train, test, and validation directories\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n    os.makedirs(val_dir, exist_ok=True)\n    os.makedirs(train_lbl_dir, exist_ok=True)\n    os.makedirs(test_lbl_dir, exist_ok=True)\n    os.makedirs(val_lbl_dir, exist_ok=True)\n    \n    \n\n    # Copy files to the corresponding directories\n    for i, img_file in enumerate(image_files):        \n        img_title = img_file.split('.')[0]\n        lbl_file = img_title + '.txt'\n        \n        if lbl_file in labels_file:   \n            \n            if i < num_train:\n                dest_img_dir = train_dir\n                dest_lbl_dir = train_lbl_dir\n            elif i < num_train + num_test:\n                dest_img_dir = test_dir\n                dest_lbl_dir = test_lbl_dir\n            else:\n                dest_img_dir = val_dir\n                dest_lbl_dir = val_lbl_dir\n\n            # Copy file (both image and label)\n            shutil.copy(os.path.join(img_source_dir, img_file), os.path.join(dest_img_dir, img_file))\n            shutil.copy(os.path.join(lbl_source_dir, lbl_file), os.path.join(dest_lbl_dir, lbl_file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_dataset(dino_imgs_path,\n              dino_lbls_path,\n              train_dir,\n              test_dir,\n              val_dir,\n              train_lbl_dir,\n              test_lbl_dir,\n              val_lbl_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Create Config File for YOLO --------------------------------------------------\nconfig = {\n    'names': ['food'],\n    'nc': 1,\n    'train': 'yolo_train/images',\n    'val': 'yolo_valid/images',\n    'test': 'yolo_test/images'\n}\n\nwith open(data_config_file, 'w') as f:\n    yaml.dump(config, f)\n\n    \ntest_config = {\n    'names': ['food'],\n    'nc': 1,\n    'train': 'yolo_train/images',\n    'val': 'yolo_test/images',    \n}\n\nwith open(test_data_config_file, 'w') as f:\n    yaml.dump(test_config, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- DS Size ------------------------------------------------------------------\ntrain_size = len([name for name in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, name))])\nval_size = len([name for name in os.listdir(val_dir) if os.path.isfile(os.path.join(val_dir, name))])\ntest_size = len([name for name in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, name))])\n\nprint(f'train size:{train_size}\\nvalidation size:{val_size}\\ntest size:{test_size}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Train, EValuate, and Save Results -----------------------------------------------------\ndef run_yolo(model , project_name, results_file):\n    \n    #-- Create DF for save results --\n    cols_names = ['val_or_test','conf', 'iou', 'map_50_95', 'map_50', 'map_75', 'maps']        \n    df_results = pd.DataFrame(columns=cols_names)\n    \n    #-- Train --\n    print('Training Model ---------------------------------------------------------')\n    model.train(data = data_config_file,\n              epochs = NUM_EPOCHS,\n              device = DEVICE,\n              val = True,\n              save = True,\n              exist_ok = True,\n              plots=True,\n              project = project_name,\n              name = 'train')\n    \n    #-- load best model --\n    best_model_file = output_path + project_name + '/train/weights/best.pt'\n    best_model = YOLO(best_model_file) \n    \n    #-- Evaluate Model on Val Data --\n    print('Evaluating Model On Val Data --------------------------------------------')\n    metrics = best_model.val(data = data_config_file,\n                             device = DEVICE,\n                             project = project_name,\n                             name = 'validation')\n\n    map_50_95 = metrics.box.map\n    map_50 = metrics.box.map50\n    map_75 = metrics.box.map75\n    maps = metrics.box.maps #--a list contains map50-95 of each category --\n    \n    results = {'val_or_test': 'val',\n               'conf':None,\n               'iou':None,\n               'map_50_95':map_50_95,\n               'map_50':map_50,\n               'map_75':map_75,\n               'maps':maps}\n\n    new_df = pd.DataFrame(results, index=[0])\n    df_results = pd.concat([df_results, new_df], ignore_index=True)   \n\n    print(f'map_50_95:{map_50_95}\\nmap_50:{map_50}\\nmap_75:{map_75}\\nmaps:{maps}')\n\n    #-- Evaluate Model Test Data --\n    print('Evaluating Model On Test Data --------------------------------------------')    \n    metrics = best_model.val(data = test_data_config_file,\n                             conf = CONF_THRESHOLD,\n                             iou = IOU_THRESHOLD,\n                             device = DEVICE,\n                             project = project_name,\n                             name = 'test')\n    \n    map_50_95 = metrics.box.map\n    map_50 = metrics.box.map50\n    map_75 = metrics.box.map75\n    maps = metrics.box.maps #--a list contains map50-95 of each category --  \n    results = {'val_or_test': 'test',\n               'conf':CONF_THRESHOLD,\n               'iou':IOU_THRESHOLD,\n               'map_50_95':map_50_95,\n               'map_50':map_50,\n               'map_75':map_75,\n               'maps':maps}\n    new_df = pd.DataFrame(results)\n    df_results = pd.concat([df_results, new_df], ignore_index=True)   \n    print(f'\\t\\tmap_50_95:{map_50_95}\\nmap_50:{map_50}\\nmap_75:{map_75}\\nmaps:{maps}')\n            \n    #-- Save DF Rsults --\n    df_results.to_csv(output_path + results_file, index=False)            \n\n    \n    #-- Run Best Model on Test Images and Save Results --\n    print('Running Model on Test Images and Saving Results ----------------------------------')\n    best_model.predict(source = test_dir,\n                       conf = CONF_THRESHOLD,     \n                       iou = IOU_THRESHOLD,\n                       show = False,\n                       save= True,\n                       project= project_name +'/prediction_results',\n                       name='predictions')   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = YOLO(\"yolov8m.pt\") \nrun_yolo(model =  model,\n    project_name = PROJECT,\n    results_file = 'yolo_results.csv')\n\n#-- log --\nprint('Finished Successfully ;)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}